{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Collecting Job Data Using APIs**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Collect job data using Jobs API\n",
    "*   Store the collected data into an excel spreadsheet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><strong>Note: Before starting with the assignment make sure to read all the instructions and then move ahead with the coding part.</strong>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the actual lab, firstly you need to click on the [Jobs_API](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/Jobs_API.ipynb) notebook link. The file contains flask code which is required to run the Jobs API data.\n",
    "\n",
    "Now, to run the code in the file that opens up follow the below steps.\n",
    "\n",
    "Step1: Download the file. \n",
    "\n",
    "Step2: Upload the file into your current Jupyter environment using the upload button in your Jupyter interface. Ensure that the file is in the same folder as your working .ipynb file.\n",
    "\n",
    "Step 2: If working in a local Jupyter environment, use the \"Upload\" button in your Jupyter interface to upload the Jobs_API notebook into the same folder as your current .ipynb file.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/Upload.PNG\">\n",
    "\n",
    "Step3:  Open the Jobs_API notebook, and run all the cells to start the Flask application. Once the server is running, you can access the API from the URL provided in the notebook.\n",
    "\n",
    "If you want to learn more about flask, which is optional, you can click on this link [here](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/FLASK_API.md.html).\n",
    "\n",
    "Once you run the flask code, you can start with your assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Used in this Assignment\n",
    "\n",
    "The dataset used in this lab comes from the following source: https://www.kaggle.com/promptcloud/jobs-on-naukricom under the under a **Public Domain license**.\n",
    "\n",
    "> Note: We are using a modified subset of that dataset for the lab, so to follow the lab instructions successfully please use the dataset provided with the lab, rather than the dataset from the original source.\n",
    "\n",
    "The original dataset is a csv. We have converted the csv to json as per the requirement of the lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-Up Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you attempt the actual lab, here is a fully solved warmup exercise that will help you to learn how to access an API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an API, let us find out who currently are on the International Space Station (ISS).<br> The API at [http://api.open-notify.org/astros.json](http://api.open-notify.org/astros.json?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2021-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ) gives us the information of astronauts currently on ISS in json format.<br>\n",
    "You can read more about this API at [http://open-notify.org/Open-Notify-API/People-In-Space/](http://open-notify.org/Open-Notify-API/People-In-Space?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2021-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests # you need this module to make an API call\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_url = \"http://api.open-notify.org/astros.json\" # this url gives use the astronaut data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(api_url) # Call the API using the get method and store the\n",
    "                                # output of the API call in a variable called response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if response.ok:             # if all is well() no errors, no network timeouts)\n",
    "    data = response.json()  # store the result in json format in a variable called data\n",
    "                            # the variable data is of type dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': [{'craft': 'ISS', 'name': 'Oleg Kononenko'}, {'craft': 'ISS', 'name': 'Nikolai Chub'}, {'craft': 'ISS', 'name': 'Tracy Caldwell Dyson'}, {'craft': 'ISS', 'name': 'Matthew Dominick'}, {'craft': 'ISS', 'name': 'Michael Barratt'}, {'craft': 'ISS', 'name': 'Jeanette Epps'}, {'craft': 'ISS', 'name': 'Alexander Grebenkin'}, {'craft': 'ISS', 'name': 'Butch Wilmore'}, {'craft': 'ISS', 'name': 'Sunita Williams'}, {'craft': 'Tiangong', 'name': 'Li Guangsu'}, {'craft': 'Tiangong', 'name': 'Li Cong'}, {'craft': 'Tiangong', 'name': 'Ye Guangfu'}], 'number': 12, 'message': 'success'}\n"
     ]
    }
   ],
   "source": [
    "print(data)   # print the data just to check the output or for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of astronauts currently on ISS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(data.get('number'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the names of the astronauts currently on ISS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 astronauts on ISS\n",
      "And their names are :\n",
      "Oleg Kononenko\n",
      "Nikolai Chub\n",
      "Tracy Caldwell Dyson\n",
      "Matthew Dominick\n",
      "Michael Barratt\n",
      "Jeanette Epps\n",
      "Alexander Grebenkin\n",
      "Butch Wilmore\n",
      "Sunita Williams\n",
      "Li Guangsu\n",
      "Li Cong\n",
      "Ye Guangfu\n"
     ]
    }
   ],
   "source": [
    "astronauts = data.get('people')\n",
    "print(\"There are {} astronauts on ISS\".format(len(astronauts)))\n",
    "print(\"And their names are :\")\n",
    "for astronaut in astronauts:\n",
    "    print(astronaut.get('name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope the warmup was helpful. Good luck with your next lab!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Collect Jobs Data using Jobs API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: Determine the number of jobs currently open for various technologies  and for various locations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the number of job postings for the following locations using the API:\n",
    "\n",
    "* Los Angeles\n",
    "* New York\n",
    "* San Francisco\n",
    "* Washington DC\n",
    "* Seattle\n",
    "* Austin\n",
    "* Detroit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (3.1.3)\n",
      "Requirement already satisfied: et-xmlfile in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (execute this cell first)\n",
    "!pip install openpyxl\n",
    "\n",
    "# Import required libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json#### Write a function to get the number of jobs for the Python technology.<br>\n",
    "> Note: While using the lab you need to pass the **payload** information for the **params** attribute in the form of **key** **value** pairs.\n",
    "  Refer the ungraded **rest api lab** in the course **Python for Data Science, AI & Development**  <a href=\"https://www.coursera.org/learn/python-for-applied-data-science-ai/ungradedLti/P6sW8/hands-on-lab-access-rest-apis-request-http?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\">link</a>\n",
    "  \n",
    " ##### The keys in the json are \n",
    " * Job Title\n",
    " \n",
    " * Job Experience Required\n",
    " \n",
    " * Key Skills\n",
    " \n",
    " * Role Category\n",
    " \n",
    " * Location\n",
    " \n",
    " * Functional Area\n",
    " \n",
    " * Industry\n",
    " \n",
    " * Role \n",
    " \n",
    "You can also view  the json file contents  from the following <a href = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\">json</a> URL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de vagas carregadas: 27005\n"
     ]
    }
   ],
   "source": [
    "# API URL\n",
    "api_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\"\n",
    "\n",
    "# Função auxiliar para carregar dados da API\n",
    "def fetch_job_data():\n",
    "    \"\"\"\n",
    "    Busca os dados de jobs da API e retorna como lista de dicionários\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Erro ao acessar API: {response.status_code}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na requisição: {e}\")\n",
    "        return []\n",
    "\n",
    "# Carregar dados uma vez para usar nas funções\n",
    "job_data = fetch_job_data()\n",
    "print(f\"Total de vagas carregadas: {len(job_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the function for Python and checking if it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Python', 1188)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_number_of_jobs_T(technology):\n",
    "    \"\"\"\n",
    "    Conta o número de vagas que mencionam uma tecnologia específica\n",
    "    \"\"\"\n",
    "    number_of_jobs = 0\n",
    "    technology_lower = technology.lower()\n",
    "    \n",
    "    for job in job_data:\n",
    "        # Busca a tecnologia em Key Skills (principal campo)\n",
    "        key_skills = job.get('Key Skills', '').lower()\n",
    "        job_title = job.get('Job Title', '').lower()\n",
    "        \n",
    "        # Verifica se a tecnologia está presente nas habilidades ou título\n",
    "        if technology_lower in key_skills or technology_lower in job_title:\n",
    "            number_of_jobs += 1\n",
    "    \n",
    "    return technology, number_of_jobs\n",
    "# Calling the function for Python and checking if it works\n",
    "get_number_of_jobs_T(\"Python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Write a function to find number of jobs in US for a location of your choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Los Angeles', 640)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_number_of_jobs_L(location):\n",
    "    \"\"\"\n",
    "    Conta o número de vagas em uma localização específica\n",
    "    \"\"\"\n",
    "    number_of_jobs = 0\n",
    "    location_lower = location.lower()\n",
    "    \n",
    "    for job in job_data:\n",
    "        job_location = job.get('Location', '').lower()\n",
    "        if location_lower in job_location:\n",
    "            number_of_jobs += 1\n",
    "    \n",
    "    return location, number_of_jobs\n",
    "# Call the function for Los Angeles and check if it is working\n",
    "get_number_of_jobs_L(\"Los Angeles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function for Los Angeles and check if it is working.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the results in an excel file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the API for all the given technologies above and write the results in an excel spreadsheet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not know how create excel file using python, double click here for **hints**.\n",
    "\n",
    "<!--\n",
    "\n",
    "from openpyxl import Workbook        # import Workbook class from module openpyxl\n",
    "wb=Workbook()                        # create a workbook object\n",
    "ws=wb.active                         # use the active worksheet\n",
    "ws.append(['Country','Continent'])   # add a row with two columns 'Country' and 'Continent'\n",
    "ws.append(['Eygpt','Africa'])        # add a row with two columns 'Egypt' and 'Africa'\n",
    "ws.append(['India','Asia'])          # add another row\n",
    "ws.append(['France','Europe'])       # add another row\n",
    "wb.save(\"countries.xlsx\")            # save the workbook into a file called countries.xlsx\n",
    "\n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a python list of all technologies for which you need to find the number of jobs postings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a python list of all technologies\n",
    "technologies = [\n",
    "    \"C\", \"C#\", \"C++\", \"Java\", \"JavaScript\", \"Python\", \n",
    "    \"Scala\", \"Oracle\", \"SQL Server\", \"MySQL Server\", \"PostgreSQL\", \"MongoDB\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROCESSANDO TECNOLOGIAS ===\n",
      "C: 25973 jobs\n",
      "C#: 555 jobs\n",
      "C++: 513 jobs\n",
      "Java: 3547 jobs\n",
      "JavaScript: 2254 jobs\n",
      "Python: 1188 jobs\n",
      "Scala: 149 jobs\n",
      "Oracle: 928 jobs\n",
      "SQL Server: 431 jobs\n",
      "MySQL Server: 0 jobs\n",
      "PostgreSQL: 88 jobs\n",
      "MongoDB: 210 jobs\n",
      "\n",
      "DataFrame de Tecnologias:\n",
      "      Technology  Number_of_Jobs\n",
      "0              C           25973\n",
      "1             C#             555\n",
      "2            C++             513\n",
      "3           Java            3547\n",
      "4     JavaScript            2254\n",
      "5         Python            1188\n",
      "6          Scala             149\n",
      "7         Oracle             928\n",
      "8     SQL Server             431\n",
      "9   MySQL Server               0\n",
      "10    PostgreSQL              88\n",
      "11       MongoDB             210\n"
     ]
    }
   ],
   "source": [
    "# Criar DataFrame para armazenar resultados de tecnologias\n",
    "tech_results = []\n",
    "\n",
    "print(\"=== PROCESSANDO TECNOLOGIAS ===\")\n",
    "for technology in technologies:\n",
    "    tech_name, job_count = get_number_of_jobs_T(technology)\n",
    "    tech_results.append({'Technology': tech_name, 'Number_of_Jobs': job_count})\n",
    "    print(f\"{tech_name}: {job_count} jobs\")\n",
    "\n",
    "# Criar DataFrame\n",
    "df_technologies = pd.DataFrame(tech_results)\n",
    "print(\"\\nDataFrame de Tecnologias:\")\n",
    "print(df_technologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PROCESSANDO LOCALIZAÇÕES ===\n",
      "Los Angeles: 640 jobs\n",
      "New York: 3226 jobs\n",
      "San Francisco: 435 jobs\n",
      "Washington DC: 5316 jobs\n",
      "Seattle: 3375 jobs\n",
      "Austin: 434 jobs\n",
      "Detroit: 3945 jobs\n",
      "\n",
      "DataFrame de Localizações:\n",
      "        Location  Number_of_Jobs\n",
      "0    Los Angeles             640\n",
      "1       New York            3226\n",
      "2  San Francisco             435\n",
      "3  Washington DC            5316\n",
      "4        Seattle            3375\n",
      "5         Austin             434\n",
      "6        Detroit            3945\n"
     ]
    }
   ],
   "source": [
    "# Processar localizações\n",
    "locations = [\"Los Angeles\", \"New York\", \"San Francisco\", \"Washington DC\", \"Seattle\", \"Austin\", \"Detroit\"]\n",
    "\n",
    "loc_results = []\n",
    "\n",
    "print(\"=== PROCESSANDO LOCALIZAÇÕES ===\")\n",
    "for location in locations:\n",
    "    loc_name, job_count = get_number_of_jobs_L(location)\n",
    "    loc_results.append({'Location': loc_name, 'Number_of_Jobs': job_count})\n",
    "    print(f\"{loc_name}: {job_count} jobs\")\n",
    "\n",
    "# Criar DataFrame\n",
    "df_locations = pd.DataFrame(loc_results)\n",
    "print(\"\\nDataFrame de Localizações:\")\n",
    "print(df_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo job-postings.xlsx criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Salvar em Excel usando pandas (mais compatível)\n",
    "with pd.ExcelWriter('job-postings.xlsx', engine='openpyxl') as writer:\n",
    "    df_technologies.to_excel(writer, sheet_name='Technologies', index=False)\n",
    "    df_locations.to_excel(writer, sheet_name='Locations', index=False)\n",
    "\n",
    "print(\"Arquivo job-postings.xlsx criado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos CSV criados:\n",
      "- technologies_jobs.csv\n",
      "- locations_jobs.csv\n"
     ]
    }
   ],
   "source": [
    "# Alternativa: Salvar em CSV (sempre funciona)\n",
    "df_technologies.to_csv('technologies_jobs.csv', index=False)\n",
    "df_locations.to_csv('locations_jobs.csv', index=False)\n",
    "\n",
    "print(\"Arquivos CSV criados:\")\n",
    "print(\"- technologies_jobs.csv\")\n",
    "print(\"- locations_jobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TOP 5 TECNOLOGIAS ===\n",
      "   Technology  Number_of_Jobs\n",
      "0           C           25973\n",
      "3        Java            3547\n",
      "4  JavaScript            2254\n",
      "5      Python            1188\n",
      "7      Oracle             928\n",
      "\n",
      "=== TOP 5 LOCALIZAÇÕES ===\n",
      "        Location  Number_of_Jobs\n",
      "3  Washington DC            5316\n",
      "6        Detroit            3945\n",
      "4        Seattle            3375\n",
      "1       New York            3226\n",
      "0    Los Angeles             640\n"
     ]
    }
   ],
   "source": [
    "# Mostrar top 5 tecnologias\n",
    "print(\"=== TOP 5 TECNOLOGIAS ===\")\n",
    "top_tech = df_technologies.sort_values('Number_of_Jobs', ascending=False).head()\n",
    "print(top_tech)\n",
    "\n",
    "print(\"\\n=== TOP 5 LOCALIZAÇÕES ===\")\n",
    "top_loc = df_locations.sort_values('Number_of_Jobs', ascending=False).head()\n",
    "print(top_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the similar way, you can try for below given technologies and results  can be stored in an excel sheet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the number of job postings for the following languages using the API:\n",
    "\n",
    "*   C\n",
    "*   C#\n",
    "*   C++\n",
    "*   Java\n",
    "*   JavaScript\n",
    "*   Python\n",
    "*   Scala\n",
    "*   Oracle\n",
    "*   SQL Server\n",
    "*   MySQL Server\n",
    "*   PostgreSQL\n",
    "*   MongoDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISE COMPLETA DE TECNOLOGIAS ===\n",
      "C: 25973 jobs\n",
      "C#: 555 jobs\n",
      "C++: 513 jobs\n",
      "Java: 3547 jobs\n",
      "JavaScript: 2254 jobs\n",
      "Python: 1188 jobs\n",
      "Scala: 149 jobs\n",
      "Oracle: 928 jobs\n",
      "SQL Server: 431 jobs\n",
      "MySQL Server: 0 jobs\n",
      "PostgreSQL: 88 jobs\n",
      "MongoDB: 210 jobs\n",
      "\n",
      "=== ANÁLISE DE LOCALIZAÇÕES ===\n",
      "Los Angeles: 640 jobs\n",
      "New York: 3226 jobs\n",
      "San Francisco: 435 jobs\n",
      "Washington DC: 5316 jobs\n",
      "Seattle: 3375 jobs\n",
      "Austin: 434 jobs\n",
      "Detroit: 3945 jobs\n",
      "\n",
      "Arquivo complete-job-analysis.xlsx criado com sucesso!\n",
      "\n",
      "=== RESUMO DOS RESULTADOS ===\n",
      "\n",
      "Tecnologias (ordenadas por número de vagas):\n",
      "      Technology  Number of Jobs\n",
      "0              C           25973\n",
      "3           Java            3547\n",
      "4     JavaScript            2254\n",
      "5         Python            1188\n",
      "7         Oracle             928\n",
      "1             C#             555\n",
      "2            C++             513\n",
      "8     SQL Server             431\n",
      "11       MongoDB             210\n",
      "6          Scala             149\n",
      "10    PostgreSQL              88\n",
      "9   MySQL Server               0\n",
      "\n",
      "Localizações (ordenadas por número de vagas):\n",
      "        Location  Number of Jobs\n",
      "3  Washington DC            5316\n",
      "6        Detroit            3945\n",
      "4        Seattle            3375\n",
      "1       New York            3226\n",
      "0    Los Angeles             640\n",
      "2  San Francisco             435\n",
      "5         Austin             434\n"
     ]
    }
   ],
   "source": [
    "# Collect the number of job postings for the following languages using the API\n",
    "all_technologies = [\n",
    "    \"C\", \"C#\", \"C++\", \"Java\", \"JavaScript\", \"Python\", \n",
    "    \"Scala\", \"Oracle\", \"SQL Server\", \"MySQL Server\", \"PostgreSQL\", \"MongoDB\"\n",
    "]\n",
    "\n",
    "locations = [\"Los Angeles\", \"New York\", \"San Francisco\", \"Washington DC\", \"Seattle\", \"Austin\", \"Detroit\"]\n",
    "\n",
    "# === PROCESSAR TECNOLOGIAS ===\n",
    "tech_data = []\n",
    "print(\"=== ANÁLISE COMPLETA DE TECNOLOGIAS ===\")\n",
    "for technology in all_technologies:\n",
    "    tech_name, job_count = get_number_of_jobs_T(technology)\n",
    "    tech_data.append({\n",
    "        'Technology': tech_name,\n",
    "        'Number of Jobs': job_count\n",
    "    })\n",
    "    print(f\"{tech_name}: {job_count} jobs\")\n",
    "\n",
    "# Criar DataFrame de tecnologias\n",
    "df_technologies = pd.DataFrame(tech_data)\n",
    "\n",
    "# === PROCESSAR LOCALIZAÇÕES ===\n",
    "loc_data = []\n",
    "print(\"\\n=== ANÁLISE DE LOCALIZAÇÕES ===\")\n",
    "for location in locations:\n",
    "    loc_name, job_count = get_number_of_jobs_L(location)\n",
    "    loc_data.append({\n",
    "        'Location': loc_name,\n",
    "        'Number of Jobs': job_count\n",
    "    })\n",
    "    print(f\"{loc_name}: {job_count} jobs\")\n",
    "\n",
    "# Criar DataFrame de localizações\n",
    "df_locations = pd.DataFrame(loc_data)\n",
    "\n",
    "# === SALVAR EM EXCEL ===\n",
    "try:\n",
    "    with pd.ExcelWriter('complete-job-analysis.xlsx', engine='openpyxl') as writer:\n",
    "        df_technologies.to_excel(writer, sheet_name='Technologies', index=False)\n",
    "        df_locations.to_excel(writer, sheet_name='Locations', index=False)\n",
    "    print(\"\\nArquivo complete-job-analysis.xlsx criado com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao criar Excel: {e}\")\n",
    "    # Fallback para CSV\n",
    "    df_technologies.to_csv('technologies-analysis.csv', index=False)\n",
    "    df_locations.to_csv('locations-analysis.csv', index=False)\n",
    "    print(\"\\nArquivos CSV criados:\")\n",
    "    print(\"- technologies-analysis.csv\")\n",
    "    print(\"- locations-analysis.csv\")\n",
    "\n",
    "# === MOSTRAR RESULTADOS ===\n",
    "print(\"\\n=== RESUMO DOS RESULTADOS ===\")\n",
    "print(\"\\nTecnologias (ordenadas por número de vagas):\")\n",
    "df_tech_sorted = df_technologies.sort_values('Number of Jobs', ascending=False)\n",
    "print(df_tech_sorted)\n",
    "\n",
    "print(\"\\nLocalizações (ordenadas por número de vagas):\")\n",
    "df_loc_sorted = df_locations.sort_values('Number of Jobs', ascending=False)\n",
    "print(df_loc_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ayushi Jain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n",
    "\n",
    "Lakshmi Holla\n",
    "\n",
    "Malika\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- | \n",
    "| 2022-01-19        | 0.3     | Lakshmi Holla        | Added changes in the markdown      |\n",
    "| 2021-06-25        | 0.2     | Malika            | Updated GitHub job json link       |\n",
    "| 2020-10-17        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |--!>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "prev_pub_hash": "61a35a07ad98492b710274ae0e52a0fdce2221e88e366133dd4a20370680fa8f"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
